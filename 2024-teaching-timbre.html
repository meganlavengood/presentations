<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>Layers of Meaning: Teaching Instrumentation and Texture</title>

  <meta name="description" content="Presentation">
  <meta name="author" content="Megan Lavengood">

  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <link rel="stylesheet" href="libs/reveal.js/4.3.1/reset.css">
  <link rel="stylesheet" href="libs/reveal.js/4.3.1/reveal.css">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

  <!-- highlight Theme -->

  <link rel="stylesheet" href="libs/highlight.js/11.3.1/styles/monokai.min.css">



  <link rel="stylesheet" href="libs/reveal.js/4.3.1/plugin/chalkboard/style.css">



  <link rel="stylesheet" href="libs/reveal.js/4.3.1/plugin/customcontrols/style.css">





  <!-- Revealjs Theme -->

  <link rel="stylesheet" href="libs/reveal.js/4.3.1/theme/solarized.css" id="theme">



  <link rel="stylesheet" href="libs/styles/tasklist.css">
  <link rel="stylesheet" href="libs/styles/iota.css">
  <link rel="stylesheet" href="libs/styles/layout.css">


  <!-- Revealjs Theme -->


  <!-- css list -->




</head>

<body>



  <div class="reveal">

    <!-- Any section element inside of this container is displayed as a slide -->
    <div class="slides">





      <section>
        <section>
          <link rel="stylesheet" href="custom/custom.css">

          <h1 class="r-fit-text">Megan Lavengood, George Mason University</h1>

          <p>Megan Lavengood</p>

          <p>Texas Society for Music Theory, February 23, 2024</p>

        </section>

        <section>

          <h2><a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list">Bibliography</a></h2>

          <p><a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list"><img src="/teaching-timbre/bibqr-teaching-timbre.svg" width="50%"></a></p>

        </section>


      </section>





      <section>

        <!-- [sufjan slide] -->
        <aside class='notes' data-markdown>
          I think you’re supposed to begin these things with a relatable vignette, so here is mine. When I first began studying music theory, like a lot of new students, I was interested in using music theory and analysis to explore what made my like my favorite music, and at that time, my favorite music was Sufjan Stevens and especially his 2005 concept album Illinois. And what I liked so much about it was the fragile and expressive quality of Sufjan’s voice and his broad instrumentation, including the expected guitar, bass, keyboard, and drums but also oboe, banjo, trumpet, vibraphone, and things like that. I’m sorry to say that when I first asked a mentor about studying Sufjan’s vocal timbre, particularly the way he renders his vowels, they steered me away from the topic, saying that it was a linguistics project and not a music theory project.
        </aside>
      </section>





      <section>

        <ul>
          <li class="fragment">Music theory as an area of research has become much more broad and inclusive.</li>
          <li class="fragment">But it’s difficult to reflect this in the classroom without resources.</li>
        </ul>
        <aside class='notes' data-markdown>
          So much has changed since then. I highly doubt that mentor would say the same thing today. Timbre studies have exploded since about 2015, and in the past couple years, voice in particular has been enjoying its moment. I just got a call for papers for an international conference called “New Perspectives on the Musical Analysis of the Voice,” for example.</p>

          [click]

          But oftentimes, the broad nature of our academic discipline is not reflected in the curriculum that we teach at our institutions, especially at the undergraduate level. Why is this? To be clear, I definitely don't think it's from a lack of desire to change. The reason I wanted to give this talk on this subject today is because I think people <i>are</i> ready and willing to change the undergraduate theory curriculum.

          But here's one potential roadblock: teachers are lacking practical and simple ways to add cutting-edge content in their classrooms when the topics are not covered in textbooks, workbooks, and standard theory pedagogy training. And while professional music theorists may have the resources to overcome this, we all know that it's not just tenure-track theory faculty teaching these courses, but also performance faculty, contingent faculty, and graduate students who are not supported enough to do this kind of labor.

          And there are more reasons to start teaching timbre beyond simply reflecting the field’s academic interests—I believe timbre can be a part of addressing broader shortcomings in music school curricula. In case you’ve been blissfully unaware of the prominent themes in current musicological discourse on this topic, I will quickly articulate what I see as the principal critiques that are relevant to my talk today.
        </aside>
      </section>





      <section>
        <section>

          <h2 class="r-fit-text">Common critiques of theory and aural skills</h2>

          <ol>
            <li class="fragment">Theory classes should discuss more than just classical music.</li>
            <li class="fragment">Theory classes spend too much time on form and (especially) pitch.</li>
            <li class="fragment">Theory classes alienate our students, and function as weeder classes that are gatekeeping certain people from studying music in an academic setting, to the detriment of our departments and our field.</li>
          </ol>
          <aside class='notes' data-markdown>

            <p>[read slide]</p>
          </aside>
        </section>

        <section>

          <p><a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list">Loren Kajikawa<br>“The Possessive Investment in Classical Music: <br>Confronting Legacies of White Supremacy in U.S. Schools and Departments of Music&quot;<br>(2019)</a></p>
          <aside class='notes' data-markdown>
            These problems stem from the fact that, as Loren Kajikawa puts it, the vast majority of music departments have invested so much in classical music, even while the influence, significance, and even dominance of other styles of music has grown over the past 100 years.
          </aside>
        </section>

        <section>

          <h3>Motivations</h3>

          <ul>
            <li class="fragment">Practical concerns about enrollment dips and budget</li>
            <li class="fragment">Ethical concerns about imperialism and exclusion</li>
          </ul>
          <aside class='notes' data-markdown>
            There's eminently practical concerns that can motivate these critiques. Most of our music programs have seen enrollment dips (because of Covid and budget cuts and general undervaluing of learning for learning sake—but that’s a whole other presentation). As programs realize they need to reach out to more people, they are reconsidering this exclusive focus on classical music. For example, we can’t assume all incoming freshmen have taken years of private lessons on their instruments, so programs may remove audition requirements altogether or add applied music technology as a primary instrument option. Programs may develop a music BA that is focused more on music studies than on performance. When programs do these sorts of things, it throws the traditional music theory curriculum into question. If students have not auditioned on an instrument, or don’t even play a traditional music school instrument, then we can no longer assume our students have spent years honing their ability to read notation. If a substantial chunk of your student population is majoring in music technology, music therapy, music business, or music studies, then classical music is unlikely to be relevant to their academic or career goals. A theory curriculum needs to be equipped to deal with this if the music department is going to stay afloat financially.

            <p>But there’s also a philosophical, ethical, moral concern that can spur the same critiques: the concern that theory is a colonizing force in music studies and music making. This struck me most when I read Dylan Robinson’s book, <em>Hungry Listening</em>, and Robin Attas’s work on decolonizing music curricula.</p>
          </aside>
        </section>

        <section>

          <p><a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list">Robin Attas<br>“The Many Paths of Decolonization:<br>Exploring Colonizing and Decolonizing Analyses of <br>A Tribe Called Red’s ‘How I Feel’”<br>2022</a></p>

          <hr>

          <p><a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list">Dylan Robinson<br><em>Hungry Listening:<br>Resonant Theory for Indigenous Sound Studies</em><br>2020</a></p>
          <aside class='notes' data-markdown>
            One thing that makes theory “colonizing” according to these authors is the way we break musical works down into component parts to study them out-of-time and in detail. While this seems ethically consistent with European classical music, for example—a culture can't colonize itself, as far as I know—there are other kinds of music in which this approach would be more ethically ambiguous or even clearly inappropriate.

            And if close analysis is what music theory is—and I think that’s often true—then honestly, I wonder if it's even possible for music theory to be decolonizing in any way. Certainly I’m not the best person to be reflecting on this, since my positionality as a white woman with the privilege of private piano lessons and traditional university music study means that I have a pretty substantial conflict of interest that I can’t pretend I am able to set aside. Like, I’m going to be pretty loath to admit that the subject I’ve essentially spent my entire life specializing in is now irrelevant and harmful to a 21st-century world. So bearing that big disclaimer in mind,
          </aside>
        </section>

        <section>

          <h3>What can we do?</h3>

          <ul>
            <li class="fragment">Appropriately circumscribe our work and recognize our positionality</li>
            <li class="fragment">Learn how to look at music in new and more holistic ways</li>
          </ul>
          <aside class='notes' data-markdown>
            I guess my take on it is that, even if music theorists can't be truly decolonizing in our work, we can at a minimum CLICK appropriately circumscribe our work—this is the music we can ethically address, and this is the music we cannot—and CLICK even better, we can learn from the literature and philosophy of decolonization how to look upon music in new ways. If we do that, not only would we do less harm, but we would also enrich our field.

            <p>One example of what I think of as a kind of colonizer’s outlook on music theory is when people who have only learned a little bit of music theory decide that they want to write music that emulates another style of music with which they’re not terribly familiar. This seems to be a common impulse among budding composers, especially nowadays in this era of musical omnivorousness.</p>
          </aside>
        </section>

        <section data-background-color="black">
          <!-- .slide: data-background-color="black" -->
          <div class="container">
            <div class="col">
              <img src="/teaching-timbre/reddit-1.png" alt="screenshot 1" width="100%">
            </div>
            <div class="col">
              <img src="/teaching-timbre/reddit-2.png" alt="screenshot 2" width="100%">
            </div>
          </div>
          <aside class='notes' data-markdown>
            I’m thinking in particular about the time I spent as a moderator of the music theory subreddit. There, I regularly saw posts from users who wanted help understanding how they could create an Arabic sound, or a psychedelic sound, or whatever. And their question would be “what scales do I use?” or “what chords do I use?”, because they were posting in a music theory subreddit for help, and they believed that music theory was based around scales and chords. The question is fundamentally flawed because really what makes these things sound like they are participating in those cultures or genres doesn't have very much to do with scales or chords. And now we’re getting to my pet projects, because in my opinion, emulating a style generally has more to do with timbre and instrumentation and texture.
          </aside>
        </section>

        <section>
          <aside class='notes' data-markdown>
            We're already running up against the problem I brought up a minute ago, that music theory can't really be decolonizing. Because even if I go on to answer this question with information about timbre and texture, that answer is still trying to make those other kinds of music digestible for a newcomer, in precisely the kind of way that Dylan Robinson criticizes—this is basically a quintessential example of “hungry listening” and extractive work. So to be clear, I am not saying that the study of timbre would fix all our problems. But I do think that broadening the tools that we introduce in basic music theory to include timbre and texture would promote a more comprehensive understanding of what goes on in music, and that’s a good and helpful thing.
          </aside>
        </section>


      </section>





      <section>

        <h2>Talk outline</h2>

        <ol>
          <li class="fragment">Define timbre’s multifaceted nature</li>
          <li class="fragment">Suggest how different facets of timbre analysis would fit into different parts of an undergraduate music major curriculum</li>
          <li class="fragment">Offer practical resources for incorporating timbre study into your own curricula, based on my own experience and expertise</li>
        </ol>
        <aside class='notes' data-markdown>
          So far I’ve been mostly philosophizing, and I do want to do some of that in this talk, but I also want to be concrete and practical. For the remainder of the talk, my plan is to

          read slide

          <p>I’ll conclude by reflecting on why I believe that timbre belongs in music theory classrooms and what we gain by putting it there.</p>
        </aside>
      </section>





      <section>
        <section>

          <h2 class="r-fit-text">Five “Conceptions” of timbre</h2>

          <p style="font-size: large;"><a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list">Stephen McAdams, “‘What Is Timbre?’ vs. ‘What Can We Do with Timbre?’: Picking the Right Questions” (2018)</a></p>

          <ol>
            <li class="fragment">Timbre as sound-source identification</li>
            <li class="fragment">Acoustics of timbre</li>
            <li class="fragment">Perceived timbre</li>
            <li class="fragment">Timbre semantics</li>
            <li class="fragment">Polyphonic timbre</li>
          </ol>
          <aside class='notes' data-markdown>
            Teaching timbre must first begin with defining it, and this is a notoriously tricky task. One of the most helpful definitions I’ve encountered comes from a presentation from Stephen McAdams, in which he enumerates five separate conceptions of timbre, as follows:

            - Timbre as sound-source identification, which talks about a kind of macrotimbre of each instrument—the “timbre” of a clarinet, for example.
            - Acoustics of timbre, which understands timbre as a physical and measurable phenomenon, like temperature.
            - Perceived timbre, that is, timbre as perceived in the mind of a listener. Perceived timbre is informed not just by the physical properties of the sound source but also by associations made in the listener’s mind.
            - Timbre semantics, which is focused on understanding and refining vocabularies of timbre.
            - Ensemble or polyphonic timbre; that is, consideration of the total timbre that arises from a combination of sound sources playing together.

            I'll go through each of these five conceptions in a little detail, because I think not everyone has thought through all that timbre really implies. And all of these five ways of understanding timbre are valuable scholarly fields of inquiry, but to what extent could they map onto the classes we offer undergraduate music majors? I’ll go through each.
          </aside>
        </section>

        <section>

          <h2>Perceived timbre</h2>

          <ul>
            <li class="fragment">Music perception and cognition</li>
            <li class="fragment">Cultural musicology</li>
          </ul>
          <aside class='notes'>
            First, timbre as perceived. Many studies have evidenced the perceptual nature of timbral understanding. Our ears and our minds imperfectly assess acoustic information; we make critical judgments based on our prior knowledge and priorities, and so on. The role of timbre perception can be studied through two lenses: music perception and cognition and cultural musicology. Perception and cognition uses more quantitative methods to capture the way we think about timbre—for example, a listener might be given two sound samples and asked to evaluate how similar the sounds are timbrally. I think many music curricula don't incorporate this kind of empirical study into an undergraduate curriculum; of course, one that does could approach such a study of timbre in that class.

            Cultural musicology discusses timbre and its social contexts—the way our identities and background influence how we understand and experience timbre. For example, Nina Sun Eidsheim in *The Race of Sound* discusses how, while race and thus bodies may seem to be intelligible through vocal timbre alone, it is not inherent anatomical differences, but social differences—learned behaviors—that determine vocal timbre. To study timbre from this angle would feel most at home in a musicology or ethnomusicology course, where students are already primed to discuss society's impact on our experience of music.
          </aside>
        </section>

        <section>

          <h2>Acoustics</h2>

          <ul>
            <li class="fragment">Physical, "objective" facts about sound signals</li>
            <li class="fragment">The impact of materials, spaces, etc. on timbre</li>
          </ul>
          <aside class='notes'>
            So while the complexity and malleability of timbre perception makes it feel very ineffable, there are also measurable components to timbre as well, and thus timbre can be discussed from this technical angle as well. Sound signals may be imported into spectrogram visualizers, for example, to allow an analyst to examine the physical, acoustic attributes of timbre. This is something I do in my own research, for example, on the Yamaha DX7 synthesizer and in Sega Genesis sound. This kind of work overlaps nicely with music technology classes, and it wouldn’t be impossible to implement it in a typical theory or aural skills classroom. But I imagine the technological aspect may prove to be a roadblock in some contexts: there could be difficulty in getting all students fluent with the software, and that’s presuming they all would have access to the hardware they’d need.
          </aside>
        </section>

        <section>

          <h2>Sound-source identification</h2>

          <ul>
            <li class="fragment">Great for fundamentals and aural skills; important basis for later work too</li>
            <li class="fragment">Activity: identifying instruments by ear, with increasing precision and nuance</li>
          </ul>
          <aside class='notes'>
            Timbre as sound-source identification is the most basic and essential kind of engagement with timbre. This is the part of timbre that is biological impulse and a survival skill. When we hear a sound we don’t expect, we ask ourselves, “what was that?” One time last summer, there was an extremely loud boom that rattled all the windows, and when I went outside to try to identify what had happened—did a tree fall down? was there a car crash? was that an earthquake?—I found all my neighbors outside doing the same thing and asking the same questions, and we were all on our phones, collaborating to try and satisfy our curiosity, Googling and texting geologist friends and checking Twitter. (This was back when Twitter was useful.) It turned out to have been a sonic boom caused by fighter jets flying overhead. But my point is that it’s a human instinct to categorize timbres based on their source sounds.

            <p>So given the primacy of this urge, sound-source identification seems like an appropriate skill to develop in aural skills classes and in theory fundamentals classes, and it would be a component of other discussions in higher-level coursework too. Activities could begin with simpler tasks, like distinguishing orchestral instruments from one another, but proceed to more subtle differences: telling a viola from a violin or cello, learning what different effects pedals do to an electric guitar sound, or identifying various auxiliary percussion instruments. I think this is one of the more straightforward conceptions of timbre with the clearest kinds of assessments, so this won’t be a focus for me today either, but sound-source identification is also an assumed skill for some of the activities I’ll discuss later in this talk.</p>
          </aside>
        </section>

        <section>

          <h2>Semantics</h2>

          <ul>
            <li class="fragment">Great for written theory classes</li>
            <li class="fragment">Theory already spends a lot of time establishing vocabulary; this is a natural fit</li>
          </ul>
          <aside class='notes'>
            The most natural fit for a traditional music theory curriculum is the study of timbre semantics. Learning specialized terms and how to apply them is already a large portion of what we do in theory class. One might object that timbre terminology is too variable to codify and teach, but other aspects of music theory are the same way—terms for form in pop music, chord symbols, even approaches to set theory—and yet we make decisions as teachers and commit to them in our classrooms. I will spend some time soon discussing what this might look like in classroom activities or homework assignments.
          </aside>
        </section>

        <section>

          <h2>Polyphonic Timbre</h2>

          <p style="font-size: medium;"><a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list">McAdams, Goodchild, and Soden, “A Taxonomy of Orchestral Grouping Effects Derived from Principles of Auditory Perception” (2022)</a></p>

          <ul>
            <li class="fragment">Analysis of texture: more than just “monophonic, polyphonic, homophonic”</li>
            <li class="fragment">Auditory stream analysis (ASA)</li>
          </ul>
          <aside class='notes'>
            McAdams and his coauthors call polyphonic timbre “one of the most complex, mysterious, and dazzling aspects of music.” I agree, and I think that polyphonic timbre has some of the greatest power to pique our students’ curiosity about timbre.

            <p>A prerequisite to the study of polyphonic timbre is the study of texture and what’s called “auditory scene analysis,” both of which involve grouping instruments in a larger ensemble into component “streams” of aural information. Research has shown that treating ensemble timbre as a unified entity (for example, by analyzing a spectrogram from a mixed and mastered mono or stereo recording of an orchestral work) does not adequately reflect human experience of that ensemble performance, because listeners do not in fact experience this as a unified timbre, but rather as coordinated but separate timbres. This necessitates defining those smaller streams that a listener would attend to and evaluate separately. To be clear: analysis of texture is not the same as analysis of timbre, but the two are intertwined in this way—by analyzing texture, we can determine what entities constitute a single “timbre” in a given context. This kind of timbre analysis is a natural fit for most music theory classrooms.</p>

            <p>With these grounding principles in mind, I’ll move now to the portion of my talk where I present some practical classroom resources, activities, and assessment structures that could begin to facilitate the inclusion of timbre analysis in our courses.</p>
          </aside>
        </section>


      </section>





      <section>
        <section data-auto-animate>

          <h2 class="r-fit-text">Textbooks and readings</h2>

          <p>Traditional textbooks don’t help much:</p>
          <div class="container" style="font-size: xx-large;">
            <div class="col-8">

              <ul>
                <li class="fragment"><strong>One (or one-half) chapter</strong> on texture/timbre

                  <ul>
                    <li>Benward/Saker<br>(“Texture and textural reduction”)</li>
                    <li>Laitz<br>(“Triads, Seventh Chords, and Texture”)</li>
                    <li>Roig-Francoli<br>(“The Rudiments of Harmony II: Labeling Chords. Musical Texture.”)</li>
                  </ul>
                </li>
              </ul>
            </div>
            <div class="col">

              <ul>
                <li class="fragment"><strong>No chapters on texture/timbre</strong>

                  <ul>
                    <li>Clendinning/Marvin</li>
                    <li>Aldwell/Schachter</li>
                    <li>Burstein/Straus</li>
                    <li>Kostka/Payne/Almèn</li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>

          <p class="fragment fade-up" style="font-size:larger;font-weight:bold">But Open Educational Resources (OER) do!</p>
          <aside class='notes'>
            Textbooks have a huge impact on curricula. While many of us who are professional, employed, full-time music theorists may feel comfortable developing our own materials based on scholarship we’ve read, many of us also work with people who need to rely on published or otherwise pre-existing material to teach their courses—for example, adjuncts who are not paid adequately and/or non-theorists often teach theory and aural skills classes. And the conventional textbooks focus on pitch and form. Of the seven common textbooks that make up 96% of the market share, only three include include a single chapter on texture, and two of them are still kind of about pitch, apparently (I didn’t actually look at the chapters). So the first thing I want to do is provide everyone with some excellent open educational resources (OER) that I’ve found that can support what I’m discussing today. Because they are free to access and use, you don’t have to drop your current curriculum wholesale to adopt these—they can augment your current text or curriculum without adding to your students’ costs.
          </aside>
        </section>

        <section data-auto-animate>

          <h2 class="r-fit-text">Textbooks and readings</h2>

          <p><a href="https://uen.pressbooks.pub/auralskills/#toc-part-123">Tim Chenette, <em>Foundations of Aural Skills</em></a></p>
          <iframe data-src="https://uen.pressbooks.pub/auralskills/#toc-part-123" width="100%" height="400px"></iframe>
          <aside class='notes'>
            Tim Chenette’s Foundations of Aural Skills is a fantastic OER textbook. A section of this book titled “Music’s Materiality,” which is authored by Daniel Stevens, focuses on timbre, envelope, dynamics, register, and texture.
          </aside>
        </section>

        <section data-auto-animate>

          <h2 class="r-fit-text">Textbooks and readings</h2>

          <p><a href="https://timbreandorchestration.org/modules">ACTOR Network, Timbre and Orchestration Resource</a></p>
          <iframe data-src="https://timbreandorchestration.org/modules" width="100%" height="400px"></iframe>
          <aside class='notes'>
            The ACTOR Network, a cadre of researchers mainly from McGill, has a Timbre and Orchestration Resource that they describe as “an open-access web platform supporting the analysis, creation and teaching of timbre and orchestration.” Here, they’ve set up extensive modules for teaching timbre that include learning objectives, a reading list, and ideas for assignments. There are also syllabi for entire courses focused on timbre. While this resource is maybe less plug-and-play at the undergraduate level than Open Music Theory or Foundations of Aural Skills, I’ve found it excellent for preparing my graduate seminars in timbre analysis, and it could probably work well in an upper-level undergraduate elective too.
          </aside>
        </section>

        <section data-auto-animate>

          <h2 class="r-fit-text">Textbooks and readings</h2>

          <p><a href="https://viva.pressbooks.pub/openmusictheory/part/orchestration">Mark Gotham, <em>Open Music Theory</em> v. 2, Orchestration</a></p>
          <iframe data-src="https://viva.pressbooks.pub/openmusictheory/part/orchestration/#content" width="100%" height="400px"></iframe>
          <aside class='notes'>
            And then there’s Open Music Theory version 2, which I’ve collaborated on with several coauthors. Mark Gotham has a section (however small) on orchestration.
          </aside>
        </section>

        <section data-auto-animate>

          <h2 class="r-fit-text">Textbooks and readings</h2>

          <p><a href="https://viva.pressbooks.pub/openmusictheory/chapter/texture-in-pop-music/">Megan Lavengood, chapter on texture in pop music</a></p>
          <iframe data-src="https://viva.pressbooks.pub/openmusictheory/chapter/texture-in-pop-music/#content" width="100%" height="400px"></iframe>

          <p class="r-fit-text">(Chapters on auditory scene analysis and timbre vocabulary coming soon)</p>
          <aside class='notes'>
            I had been wringing my hands a bit over adding my own research to the book, as it’s been hard for me to wrangle my ideas into what I think is a digestible, undergraduate-friendly presentation. But, partly thanks to this speaking engagement, I’ve finally worked out what I want to add. I’m now writing chapters on timbre vocabulary and on auditory scene analysis, which I hope to have up before next Fall semester. (We roll out big changes over the summer to avoid messing up peoples’ syllabi.) And I’m pilot-testing a completed chapter on texture in pop music with my current students, which I’ll show you now in detail.
          </aside>
        </section>


      </section>





      <section>

        <section data-background-iframe="https://viva.pressbooks.pub/openmusictheory/chapter/texture-in-pop-music/" data-background-interactive>
        </section>

      </section>





      <section>
        <section>

          <h2 class="r-fit-text">Activities and Assessments</h2>

          <ul>
            <li class="fragment">Music theory loves visuals: annotated scores, form charts, musical geometries, dot grids/coffee-bean grids</li>
            <li class="fragment">How to visually represent and assess timbre analyses?</li>
          </ul>
          <aside class='notes'>
            One difficulty in teaching timbre that I haven’t yet explicitly mentioned is the problem of assessment. Music theory assessments typically occur in a written format. Some music theorists—including myself, in this very talk—use the term “written music theory” to clarify that we are not talking about aural skills classes. Homework is typically a worksheet or pages from a workbook; we collect musical compositions, annotated scores, form charts, and the like.
          </aside>
        </section>

        <section data-background-image="/teaching-timbre/butler.png" data-auto-animate>
          <!-- .slide: data-background-image="/teaching-timbre/butler.png" -->
          <div style="background-color:#fffaed;">

            <h2 class="r-fit-text">Polyphonic Timbre: Functional Layers</h2>

            <ul>
              <li>Layer graphs show entrance and exit of different layers of a musical work</li>
              <li class="fragment">E.g.: Butler (2006, background), Dolan (2013), Lavengood (2021)</li>
              <li class="fragment">Probably created with Excel or programming toolkits for data science</li>
            </ul>
          </div>
          <aside class='notes'>
            Analysts of timbre and texture have often created layer graphs that show the entrances and exits of a piece’s constituent instruments with the goal of illustrating the textural organization of a piece of music. Such graphs would be a good analogue for more familiar music-theoretical artifacts, like part-writing homework or form charts. Unfortunately, while dedicated music scholars may be able to craft these visual aids themselves, the average undergraduate music major likely does not have the time, the patience, and/or the software fluency to create a chart like this by formatting cells in Microsoft Excel or using a Python script to generate a Gantt chart (these are two methods I have used myself in the past).

            <p>To help address this issue, I am working with Brian Jarvis (a music theorist and capable Javascript programmer) and Evan Williams (a data scientist) to create a web app that would allow anyone to create a layer graph with relative ease.</p>
          </aside>
        </section>


</section>





        <section>

          <section data-background-iframe="https://brianedwardjarvis.com/auralayer/home.html" data-background-interactive>
          </section>
        </section>





        <section data-auto-animate>

          <h2 class="r-fit-text">Polyphonic Timbre: Functional Layers</h2>

          <ul>
            <li class="fragment">Assignment: Identifying textural layers. Asks students to access <a href="https://splitter.fm/abakan/going-somewhere">“Going Somewhere” by Akaban on splitter.fm</a> and assign each of the song‘s stems to a functional layer.</li>
            <li class="fragment">Assignment: <a href="https://viva.pressbooks.pub/app/uploads/sites/12/2024/01/wk-visualizing-texture.pdf">Visualizing texture analysis</a>.<br>Asks students to use Auralayer to map out the instrumentation and texture of “bad guy” by Billie Eilish (2019).</li>
          </ul>

        </section>





        <section>
          <section data-auto-animate>

            <h2 class="r-fit-text">Polyphonic Timbre: Auditory Scene Analysis</h2>

            <p><img src="/teaching-timbre/mcadams_ex3.png" alt="grouping processes diagram"></p>

            <p><img src="/teaching-timbre/mcadams_ex12.png" alt="sequential grouping"></p>

          </section>

          <section data-auto-animate>

            <h2 class="r-fit-text">Polyphonic Timbre: Auditory Scene Analysis</h2>
            <p class="fragment">Assignment: Auditory scene analysis. Ask students to analyze a few passages from an orchestral work, annotate the score, and apply terminology from <a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list">McAdams et al. 2022</a>. For example:</p> 
          </section>
          <section>

            <ul>
              <li>Annotate the score to show all streams, color-coding to show which instruments integrate into a single stream.</li>
              <li>For a given integrated stream, indicate what type of blend is occuring: timbral augmentation, timbral emergence, or timbral heterogeneity.
              </li>
              <li>Find an example of auditory streams being integrated in a surface texture.</li>
              <li>Find one example for three out of the five possible timbral contrasts.</li>
            </ul>

          </section>
        </section>
          <section data-auto-animate>

            <h2>Timbre Semantics</h2>

            <ul>
              <li class="fragment">Assignment: Use aural analysis to apply terminology to provided sound samples. Possible sound samples: single orchestral instruments, synthesized sounds, unpitched percussion, famous vocalists, distorted guitar…</li>
              <li>Class discussion or free response question on how identity/background may have influenced analysis.</li>
            </ul>

          </section>


        
      <section>

      <section data-auto-animate>

        <p class="fragment">What if it was normal for the theory curriculum to look this way?</p>
        <aside class='notes'>
          Professional music theorists know how inclusive music theory as a field can be. But most people only study the fundamentals of music theory. What we include in "fundamentals" can directly determine what people believe music theory can address and what it can do.

          If we include timbre as a fundamental aspect of music theory, we will give people more appropriate tools for assessing musics that don't deal with pitch or formal complexity in the same way as European music does. This would both 1) allow us to treat those musics better, and 2) make people feel more welcome if they have more expertise in timbral nuance than pitch nuance. If we can include those perspectives, our field will continue to grow and flourish.

        </aside>
      </section>
      <section data-auto-animate>

        <p style="margin-bottom:3em;">thanks</p>

        <p style="font-size:medium;">↓ bibliography again ↓ </p>

        <p><a href="https://www.zotero.org/mlavengood/collections/TJALUVK7/item-list"><img src="/teaching-timbre/bibqr-teaching-timbre.svg" width="30%"></a></p>
      </section>
</section>

    </div>


  </div>

  <div class="line top"></div>
  <div class="line bottom"></div>
  <div class="line left"></div>
  <div class="line right"></div>

  <script src="libs/reveal.js/4.3.1/reveal.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/notes/notes.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/markdown/markdown.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/highlight/highlight.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/math/math.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/fullscreen/plugin.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/animate/plugin.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/animate/svg.min.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/anything/plugin.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/anything/Chart.min.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/anything/d3/d3.v3.min.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/anything/d3.patch.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/anything/d3/queue.v1.min.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/anything/d3/topojson.v1.min.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/anything/function-plot.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/customcontrols/plugin.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/embed-tweet/plugin.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/chart/chart.min.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/chart/plugin.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/verticator/verticator.js"></script>

  <script src="libs/reveal.js/4.3.1/plugin/zoom/zoom.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/search/search.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/menu/menu.js"></script>
  <script src="libs/reveal.js/4.3.1/plugin/chalkboard/plugin.js"></script>

  <!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/plugin.js"></script>  -->
  <!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/recorder.js"></script>-->
  <!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/RecordRTC.js"></script>-->



  <script>
    const printPlugins = [
      RevealNotes,
      RevealHighlight,
      RevealMath.MathJax3,
      RevealAnimate,
      RevealChalkboard,
      RevealEmbedTweet,
      RevealChart,
    ];

    const plugins = [...printPlugins,
      RevealZoom,
      RevealSearch,
      RevealMarkdown,
      RevealMenu,
      RevealFullscreen,
      RevealAnything,
      //RevealAudioSlideshow,
      //RevealAudioRecorder,
      RevealCustomControls,
      // poll
      // question
      // seminar
      Verticator
    ]


    // Also available as an ES module, see:
    // https://revealjs.com/initialization/
    Reveal.initialize({
      controls: true,
      controlsTutorial: true,
      controlsLayout: 'bottom-right',
      controlsBackArrows: 'faded',
      progress: true,
      slideNumber: true,
      //#showSlideNumber "all" "print" "speaker"
      hash: true, //# hash: false,
      //# respondToHashChanges: true,
      //# history: false,
      keyboard: true,
      //#keyboardCondition: null,
      overview: true,
      center: true,
      touch: true,
      loop: false,
      rtl: false,
      //#navigationMode: 'default', linear grid
      shuffle: false,
      fragments: true,
      fragmentInURL: false,
      embedded: false,
      help: true,
      //#pause: true
      showNotes: false,
      autoPlayMedia: false, // TODO fix this to a nullable value
      //#preloadIframes: null. true false
      //#autoAnimate: true
      //#autoAnimateMatcher: null,
      //#autoAnimateEasing: 'ease',
      //autoAnimateDuration: 1.0,
      //#autoAnimateUnmatched: true
      //#autoAnimateStyles: []
      autoSlide: 0, // TODO fix this to a falseable value
      autoSlideStoppable: true,
      autoSlideMethod: '0',
      defaultTiming: 120,
      mouseWheel: false,
      //#previewLinks: false
      //#postMessage: true, // TODO : this can cause issues with the vscode api ???
      //#postMessageEvents: false,
      //#focusBodyOnPageVisibilityChange: true,
      transition: 'slide',
      transitionSpeed: 'default',
      backgroundTransition: 'fade',
      //#pdfMaxPagesPerSlide: Number.POSITIVE_INFINITY,
      //#pdfSeparateFragments: true,
      //#pdfPageHeightOffset: -1,
      viewDistance: 3,
      //#mobileViewDistance: 2,
      display: 'block',
      //#hideInactiveCursor: true,
      //#hideCursorTime: 5000

      // Parallax Background
      parallaxBackgroundImage: '',
      parallaxBackgroundSize: '',
      parallaxBackgroundHorizontal: 0,
      parallaxBackgroundVertical: 0,

      //Presentation Size
      width: 960,
      height: 700,
      margin: 0.04,
      minScale: 0.2,
      maxScale: 2,
      disableLayout: false,

      audio: {
        prefix: 'audio/', // audio files are stored in the "audio" folder
        suffix: '.ogg', // audio files have the ".ogg" ending
        textToSpeechURL: null, // the URL to the text to speech converter
        defaultNotes: false, // use slide notes as default for the text to speech converter
        defaultText: false, // use slide text as default for the text to speech converter
        advance: 0, // advance to next slide after given time in milliseconds after audio has played, use negative value to not advance
        autoplay: false, // automatically start slideshow
        defaultDuration: 5, // default duration in seconds if no audio is available
        defaultAudios: true, // try to play audios with names such as audio/1.2.ogg
        playerOpacity: 0.05, // opacity value of audio player if unfocused
        playerStyle: 'position: fixed; bottom: 4px; left: 25%; width: 50%; height:75px; z-index: 33;', // style used for container of audio controls
        startAtFragment: false, // when moving to a slide, start at the current fragment or at the start of the slide
      },

      chalkboard: { // font-awesome.min.css must be available
        //src: "chalkboard/chalkboard.json",
        storage: "chalkboard-demo",
      },

      customcontrols: {
        controls: [
          {
            id: 'toggle-overview',
            title: 'Toggle overview (O)',
            icon: '<i class="fa fa-th"></i>',
            action: 'Reveal.toggleOverview();'
          }
          ,
          {
            icon: '<i class="fa fa-pen-square"></i>',
            title: 'Toggle chalkboard (B)',
            action: 'RevealChalkboard.toggleChalkboard();'
          },
          {
            icon: '<i class="fa fa-pen"></i>',
            title: 'Toggle notes canvas (C)',
            action: 'RevealChalkboard.toggleNotesCanvas();'
          }

        ]
      },
      chart: {
        defaults: {
          color: 'lightgray', // color of labels
          scale: {
            beginAtZero: true,
            ticks: { stepSize: 1 },
            grid: { color: "lightgray" }, // color of grid lines
          },
        },
        line: { borderColor: ["rgba(20,220,220,.8)", "rgba(220,120,120,.8)", "rgba(20,120,220,.8)"], "borderDash": [[5, 10], [0, 0]] },
        bar: { backgroundColor: ["rgba(20,220,220,.8)", "rgba(220,120,120,.8)", "rgba(20,120,220,.8)"] },
        pie: { backgroundColor: [["rgba(0,0,0,.8)", "rgba(220,20,20,.8)", "rgba(20,220,20,.8)", "rgba(220,220,20,.8)", "rgba(20,20,220,.8)"]] },
        radar: { borderColor: ["rgba(20,220,220,.8)", "rgba(220,120,120,.8)", "rgba(20,120,220,.8)"] },
      },
      math: {
        mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
        config: 'TeX-AMS_HTML-full',
        // pass other options into `MathJax.Hub.Config()`
        TeX: { Macros: { RR: "{\\bf R}" } }
      },
      anything: [
        {
          className: "plot",
          defaults: { width: 500, height: 500, grid: true },
          initialize: (function (container, options) { options.target = "#" + container.id; functionPlot(options) })
        },
        {
          className: "chart",
          initialize: (function (container, options) { container.chart = new Chart(container.getContext("2d"), options); })
        },
        {
          className: "anything",
          initialize: (function (container, options) { if (options && options.initialize) { options.initialize(container) } })
        },
      ],
      // Learn about plugins: https://revealjs.com/plugins/
      plugins: (window.location.search.match(/print-pdf/gi) ? printPlugins : plugins)
    });



    // Change chalkboard theme : 
    function changeTheme(input) {
      var config = {};
      config.theme = input.value;
      Reveal.getPlugin("RevealChalkboard").configure(config);
      input.blur();
    }

    // // Handle the message inside the webview
    // window.addEventListener('message', event => {

    //     const message = event.data; // The JSON data our extension sent

    //     switch (message.command) {
    //         case 'refactor':
    //             Reveal.toggleHelp();
    //     }
    // });

    if (window.location.search.match(/print-pdf-now/gi)) {
      setTimeout(() => {
        window.print();
      }, 2500);

    }
  </script>

</body>

</html>
